# UMBRELLA Training Configuration
# LLaVA-based Vision-Language Model for Brain MRI Analysis

wandb:
    API_KEY: "YOUR_API_KEY"

seed: 1234

dataset:
    train_size: 0.8
    val_size: 0.1
    test_size: 0.1
    add_context: False
    T1:
        target: ["sex"]
        img_size: [120, 120, 120]
        study_sample: ["ABCD"]
        meta_dir: ["/pscratch/sd/h/heehaw/data/1.ABCD/ABCD_phenotype_total.csv"]
        img_dir: ["/pscratch/sd/h/heehaw/data/1.ABCD/2.sMRI_freesurfer_256"]
    rsfMRI:
        target: ["sex"]
        img_size: [96, 96, 96, 24]
        study_sample: []
        img_dir: []
        dataset_split_num: 1
        sequence_length: 24
        stride_between_seq: 1
        stride_within_seq: 1
        shuffle_time_sequence: False
        input_scaling_method: "znorm_minback"
        label_scaling_method: "standardization"
        dtype: "float16"
        limit_training_samples: Null
        limit_validation_samples: Null
        limit_test_samples: Null
        balanced_training_samples: False
        balanced_validation_samples: False
        balanced_test_samples: False


model:
    # LLaVA model (not BLIP)
    hf_name: "llava-hf/llava-1.5-7b-hf"
    T1:
        patch_size: [10, 10, 10]
    rsfMRI:
        patch_size: [16, 16, 16, 3]


trainer:
    max_epochs: 50
    learning_rate: 0.00005
    warmup_steps: 500
    weight_decay: 0.01
    per_device_batch_size: 2
    gradient_accumulation_steps: 1
    gradient_checkpointing: True
    logging_steps: 1
    ckpt_dir: "./hf_results/{}/last.ckpt"
    resume_training: False
